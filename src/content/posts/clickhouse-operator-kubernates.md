---
title: ClickHouse ç³»åˆ—ï¼šKubernetes éƒ¨ç½²åˆ†æ•£å¼æ¶æ§‹
published: 2025-09-02
description: ''
image: 'https://images.prismic.io/contrary-research/ZiwDyN3JpQ5PTNpR_clickhousecover.png?auto=format,compress'
tags: [ClickHouse, Database, éµäººè³½]
category: 'software development'
draft: false 
lang: ''
---

åœ¨éå» 28 å¤©ï¼Œæˆ‘å€‘æ·±å…¥æ¢è¨äº† ClickHouse çš„å…§éƒ¨è¨­è¨ˆï¼ŒåŒ…æ‹¬ MergeTree å¼•æ“ã€ç´¢å¼•ã€æŸ¥è©¢å„ªåŒ–æŠ€å·§ï¼Œä»¥åŠä¸åŒå¼•æ“åœ¨è³‡æ–™è™•ç†ä¸Šçš„æ‡‰ç”¨ã€‚é€™äº›éƒ½å±¬æ–¼ã€Œå–®æ©Ÿæˆ–å–®ç¯€é»ã€çš„è§€é»ã€‚ç„¶è€Œï¼Œç•¶æˆ‘å€‘è¦æŠŠ ClickHouse æ”¾åˆ°**çœŸå¯¦çš„ç”Ÿç”¢ç’°å¢ƒ**ï¼Œé¢å°é«˜ä½µç™¼ã€è³‡æ–™é‡æˆé•·ã€ä»¥åŠé«˜å¯ç”¨æ€§çš„éœ€æ±‚æ™‚ï¼Œéƒ¨ç½²ç­–ç•¥å°±è®Šå¾—æ ¼å¤–é‡è¦ã€‚

å‚³çµ±éƒ¨ç½²æ–¹å¼ï¼ˆä¾‹å¦‚ç›´æ¥åœ¨ VM æˆ–è£¸æ©Ÿä¸Šå®‰è£ï¼‰é›–ç„¶ç°¡å–®ï¼Œä½†åœ¨ç¾ä»£é›²ç«¯æ¶æ§‹ä¸‹å·²ç¶“ä¸è¶³ä»¥æ»¿è¶³éœ€æ±‚ã€‚Kubernetes ä½œç‚ºäº‹å¯¦ä¸Šçš„å®¹å™¨ç·¨æ’æ¨™æº–ï¼Œæä¾›äº†è‡ªå‹•åŒ–ã€å¯æ“´å±•ã€å½ˆæ€§åŒ–çš„èƒ½åŠ›ï¼Œè€Œ **ClickHouse Operator** å‰‡è®“æˆ‘å€‘èƒ½è¼•é¬†åœ¨ Kubernetes ä¸Šç®¡ç†è¤‡é›œçš„ ClickHouse å¢é›†ã€‚

æœ¬ç¯‡æ–‡ç« æœƒé€éåœ¨å–®ä¸€ä¸»æ©Ÿä¸Šå¿«é€Ÿä½¿ç”¨ minikube å’Œ clickhouse operator æ¨¡æ“¬ Kubernates éƒ¨ç½²åˆ†æ•£å¼æ¶æ§‹ã€‚

## ç‚ºä»€éº¼è¦åœ¨ Kubernetes ä¸Šéƒ¨ç½² ClickHouseï¼Ÿ

ClickHouse æœ¬èº«çš„è¨­è¨ˆå°±éå¸¸å¿«ï¼Œä½†éš¨è‘—è³‡æ–™é‡å’Œä½¿ç”¨è€…æ•¸æˆé•·ï¼Œå–®ä¸€ç¯€é»å¾€å¾€ç„¡æ³•æ‰¿å—æ‰€æœ‰è² è¼‰ã€‚æˆ‘å€‘éœ€è¦ï¼š

* **é«˜å¯ç”¨ (HA, High Availability)**
  * ç¯€é»æ•…éšœæ™‚ï¼Œç³»çµ±èƒ½è‡ªå‹•åˆ‡æ›ï¼Œä¸å½±éŸ¿æŸ¥è©¢ã€‚
* **æ°´å¹³æ“´å±• (Horizontal Scalability)**
  * ç•¶è³‡æ–™é‡å¾ 100GB æˆé•·åˆ°æ•¸ TBï¼Œç”šè‡³ PB ç´šï¼Œèƒ½é€éæ“´å……ç¯€é»å¿«é€Ÿåˆ†æ“”å£“åŠ›ã€‚
* **è‡ªå‹•åŒ–ç¶­é‹**
  * éƒ¨ç½²ã€å‡ç´šã€ç›£æ§ã€æ»¾å‹•æ›´æ–°éƒ½å¯ä»¥é€é Kubernetes è‡ªå‹•åŒ–å®Œæˆã€‚
* **é›²åŸç”Ÿæ•´åˆ**
  * Kubernetes çš„å„ªå‹¢åœ¨æ–¼ã€Œä¸€åˆ‡çš†ç‚º APIã€ã€‚ç›£æ§ (Prometheus)ã€å„²å­˜ (PVC)ã€ç¶²è·¯ (Ingress/Service) éƒ½èƒ½èˆ‡ ClickHouse ç„¡ç¸«çµåˆã€‚

ClickHouse Operator çš„å‡ºç¾ï¼Œå°±æ˜¯ç‚ºäº†è§£æ±ºé€™äº›å•é¡Œã€‚

## ClickHouse Operator æ ¸å¿ƒæ¦‚å¿µ

ClickHouse Operator æ˜¯ç”± [Altinity](https://github.com/Altinity) èˆ‡é–‹æºç¤¾ç¾¤ç¶­è­·çš„ [Kubernetes Operator](https://github.com/Altinity/clickhouse-operator)ï¼Œä¸»è¦ç›®æ¨™æ˜¯ç°¡åŒ– ClickHouse å¢é›†çš„ç®¡ç†ã€‚

::github{repo="Altinity/clickhouse-operator"}

å®ƒçš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

* **Cluster CRD (Custom Resource Definition)**ï¼šå…è¨±ä½ ç”¨ YAML å®šç¾©å¢é›†ï¼ˆshards, replicas, storage, resourcesï¼‰ã€‚
* **è‡ªå‹•åŒ–ç®¡ç†**ï¼šå»ºç«‹ã€å‡ç´šã€åˆªé™¤ã€æ»¾å‹•æ›´æ–°ç¯€é»ã€‚
* **é«˜å¯ç”¨æ”¯æ´**ï¼šé€é Zookeeper æˆ– Keeperï¼Œæ”¯æ´ Replicated Tablesã€‚
* **ç›£æ§æ•´åˆ**ï¼šè‡ªå‹•åŒ¯å‡º metrics çµ¦ Prometheusã€‚

çµæ§‹ä¸Šï¼ŒOperator æœƒç›£æ§ Kubernetes ä¸­çš„ ClickHouseCluster è³‡æºï¼Œä¸€æ—¦åµæ¸¬åˆ°æ”¹å‹•ï¼ˆä¾‹å¦‚æ–°å¢ä¸€å€‹ replicaï¼‰ï¼Œå°±æœƒè‡ªå‹•èª¿æ•´åº•å±¤ StatefulSet èˆ‡ Podï¼Œç¢ºä¿å¢é›†ç‹€æ…‹èˆ‡å®£å‘Šå¼é…ç½®ä¸€è‡´ã€‚

## é›²ç«¯éƒ¨ç½²æ¶æ§‹è¨­è¨ˆ

åœ¨é›²ç«¯ä¸Šï¼Œæˆ‘å€‘é€šå¸¸æœƒè¨­è¨ˆä¸€å€‹å…·å‚™ä»¥ä¸‹ç‰¹æ€§çš„æ¶æ§‹ï¼š

* **åˆ†ç‰‡ (Shards) + å‰¯æœ¬ (Replicas)**
  * Shardï¼šå°‡è³‡æ–™åˆ†æ•£åˆ°ä¸åŒç¯€é»ï¼Œåˆ†æ“”å„²å­˜å£“åŠ›
  * Replicaï¼šç‚ºæ¯å€‹ shard å»ºç«‹å‰¯æœ¬ï¼Œæä¾›é«˜å¯ç”¨
  * æœ¬æ¬¡å¯¦ä½œæˆ‘å€‘ä½¿ç”¨ 1 Shard, 2 Replica æ¶æ§‹åšç‚ºæ¸¬è©¦
* **Zookeeper/Keeper ç®¡ç†**
  * å”èª¿å¢é›†çš„ä¸€è‡´æ€§ï¼ˆè¡¨æ ¼è¤‡è£½ã€åˆ†ç‰‡è³‡è¨Šï¼‰ã€‚
  * æœ¬æ¬¡å¯¦ä½œæˆ‘å€‘ä½¿ç”¨ 3 å€‹ Zookeeper
* **Persistent Volume Claims (PVC)**
  * ä¿è­‰ç¯€é»é‡å•Ÿå¾Œè³‡æ–™ä¸æœƒä¸Ÿå¤±ã€‚
  * æœ¬æ¬¡å¯¦ä½œæˆ‘å€‘æ¡ç”¨ `emptyDir` (ä½œç‚º Demo, é—œæ‰å¾Œå°±æœƒè‡ªå‹•åˆªé™¤è³‡æ–™)
* **è³‡æºé…ç½®**
  * CPU èˆ‡ Memory é™é¡ï¼Œé¿å…èˆ‡å…¶ä»–å·¥ä½œè² è¼‰ç«¶çˆ­ã€‚

æ¶æ§‹åœ–ç¤ºä¾‹ï¼š

![Zookeeper Clickhouse Structure](../../assets/posts/clickhouse-operator-kubernates/zookeeper-clickhouse-strcture.png)

> åœ–å¥½åƒæœ‰é»å¤§...

é€™æ¨£çš„è¨­è¨ˆèƒ½ç¢ºä¿ï¼š

* ä»»ä¸€ Replica å®•æ©Ÿæ™‚ï¼ŒæŸ¥è©¢ä¸æœƒä¸­æ–·
* ç•¶è³‡æ–™é‡è®Šå¤§ï¼Œå¯ä»¥æ©«å‘æ“´å±•æ–°çš„ Shard

## å¯¦ä½œç’°ç¯€

å»ºç«‹åˆ†æ•£å¼è¡¨ä¹‹å‰æœ‰å¹¾é …å‰ç½®ä½œæ¥­ï¼š
1. å®‰è£ [minikube](https://minikube.sigs.k8s.io/docs/start/?arch=%2Fwindows%2Fx86-64%2Fstable%2F.exe+download)ï¼Œæˆ‘æ˜¯ä½¿ç”¨ wsl2 (Ubuntu 24.04.2 LTS)
    * å®‰è£å¥½å¾Œå¯ä»¥ä½¿ç”¨ `minikube dashboard` é–‹å•Ÿ GUI ä»‹é¢~ (Optional)
2. å®‰è£ [ClickHouse Operator](https://github.com/Altinity/clickhouse-operator/blob/master/docs/operator_installation_details.md)
    * æˆ‘æ˜¯åªæœ‰è·‘ä¸‹é¢çš„æŒ‡ä»¤å°±å®‰è£å¥½äº†ï¼Œæƒ³çŸ¥é“ç´°ç¯€å¯ä»¥çœ‹æ–‡ä»¶æœ¬èº«æœ‰è¬›è§£éƒ¨ç½²äº†ä»€éº¼å…ƒä»¶
    ```bash
    kubectl apply -f https://raw.githubusercontent.com/Altinity/clickhouse-operator/master/deploy/operator/clickhouse-operator-install-bundle.yaml
    ``` 
3. å‰µå»º namespaceï¼Œç”¨æ–¼éš”é›¢ç’°å¢ƒ
```bash
kubectl create namespace zoo3ns
```
4. éƒ¨ç½²ä¸‰ç¯€é» Zookeeperï¼Œæ–°å¢æª”æ¡ˆå¦‚ä¸‹ï¼š

```yaml
# zookeeper-3-nodes.yaml
# Setup Service to provide access to Zookeeper for clients
apiVersion: v1
kind: Service
metadata:
  # DNS would be like zookeeper.zoons
  name: zookeeper
  labels:
    app: zookeeper
spec:
  ports:
    - port: 2181
      name: client
    - port: 7000
      name: prometheus
  selector:
    app: zookeeper
    what: node
---
# Setup Headless Service for StatefulSet
apiVersion: v1
kind: Service
metadata:
  # DNS would be like zookeeper-0.zookeepers.etc
  name: zookeepers
  labels:
    app: zookeeper
spec:
  ports:
    - port: 2888
      name: server
    - port: 3888
      name: leader-election
  clusterIP: None
  selector:
    app: zookeeper
    what: node
---
# Setup max number of unavailable pods in StatefulSet
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: zookeeper-pod-disruption-budget
spec:
  selector:
    matchLabels:
      app: zookeeper
  maxUnavailable: 1
---
# Setup Zookeeper StatefulSet
# Possible params:
# 1. replicas
# 2. memory
# 3. cpu
# 4. storage
# 5. storageClassName
# 6. user to run app
apiVersion: apps/v1
kind: StatefulSet
metadata:
  # nodes would be named as zookeeper-0, zookeeper-1, zookeeper-2
  name: zookeeper
  labels:
    app: zookeeper
spec:
  selector:
    matchLabels:
      app: zookeeper
  serviceName: zookeepers
  replicas: 3
  updateStrategy:
    type: RollingUpdate
  podManagementPolicy: OrderedReady
  template:
    metadata:
      labels:
        app: zookeeper
        what: node
      annotations:
        prometheus.io/port: '7000'
        prometheus.io/scrape: 'true'
    spec:
      affinity: {}
      containers:
        - name: kubernetes-zookeeper
          imagePullPolicy: IfNotPresent
          image: "docker.io/zookeeper:3.8.4"
          resources:
            requests:
              memory: "512M"
              cpu: "1"
            limits:
              memory: "4Gi"
              cpu: "2"
          ports:
            - containerPort: 2181
              name: client
            - containerPort: 2888
              name: server
            - containerPort: 3888
              name: leader-election
            - containerPort: 7000
              name: prometheus
          env:
            - name: SERVERS
              value: "3"

# See those links for proper startup settings:
# https://github.com/kow3ns/kubernetes-zookeeper/blob/master/docker/scripts/start-zookeeper
# https://clickhouse.yandex/docs/en/operations/tips/#zookeeper
# https://github.com/ClickHouse/ClickHouse/issues/11781
          command:
            - bash
            - -x
            - -c
            - |
              HOST=`hostname -s` &&
              DOMAIN=`hostname -d` &&
              CLIENT_PORT=2181 &&
              SERVER_PORT=2888 &&
              ELECTION_PORT=3888 &&
              PROMETHEUS_PORT=7000 &&
              ZOO_DATA_DIR=/var/lib/zookeeper/data &&
              ZOO_DATA_LOG_DIR=/var/lib/zookeeper/datalog &&
              {
                echo "clientPort=${CLIENT_PORT}"
                echo 'tickTime=2000'
                echo 'initLimit=300'
                echo 'syncLimit=10'
                echo 'maxClientCnxns=2000'
                echo 'maxTimeToWaitForEpoch=2000'
                echo 'maxSessionTimeout=60000000'
                echo "dataDir=${ZOO_DATA_DIR}"
                echo "dataLogDir=${ZOO_DATA_LOG_DIR}"
                echo 'autopurge.snapRetainCount=10'
                echo 'autopurge.purgeInterval=1'
                echo 'preAllocSize=131072'
                echo 'snapCount=3000000'
                echo 'leaderServes=yes'
                echo 'standaloneEnabled=false'
                echo '4lw.commands.whitelist=*'
                echo 'metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider'
                echo "metricsProvider.httpPort=${PROMETHEUS_PORT}"
                echo "skipACL=true"
                echo "fastleader.maxNotificationInterval=10000"
              } > /conf/zoo.cfg &&
              {
                echo "zookeeper.root.logger=CONSOLE"
                echo "zookeeper.console.threshold=INFO"
                echo "log4j.rootLogger=\${zookeeper.root.logger}"
                echo "log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender"
                echo "log4j.appender.CONSOLE.Threshold=\${zookeeper.console.threshold}"
                echo "log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout"
                echo "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n"
              } > /conf/log4j.properties &&
              echo 'JVMFLAGS="-Xms128M -Xmx4G -XX:ActiveProcessorCount=8 -XX:+AlwaysPreTouch -Djute.maxbuffer=8388608 -XX:MaxGCPauseMillis=50"' > /conf/java.env &&
              if [[ $HOST =~ (.*)-([0-9]+)$ ]]; then
                  NAME=${BASH_REMATCH[1]} &&
                  ORD=${BASH_REMATCH[2]};
              else
                  echo "Failed to parse name and ordinal of Pod" &&
                  exit 1;
              fi &&
              mkdir -pv ${ZOO_DATA_DIR} &&
              mkdir -pv ${ZOO_DATA_LOG_DIR} &&
              whoami &&
              chown -Rv zookeeper "$ZOO_DATA_DIR" "$ZOO_DATA_LOG_DIR" &&
              export MY_ID=$((ORD+1)) &&
              echo $MY_ID > $ZOO_DATA_DIR/myid &&
              for (( i=1; i<=$SERVERS; i++ )); do
                  echo "server.$i=$NAME-$((i-1)).$DOMAIN:$SERVER_PORT:$ELECTION_PORT" >> /conf/zoo.cfg;
              done &&
              if [[ $SERVERS -eq 1 ]]; then
                  echo "group.1=1" >> /conf/zoo.cfg;
              else
                  echo "group.1=1:2:3" >> /conf/zoo.cfg;
              fi &&
              for (( i=1; i<=$SERVERS; i++ )); do
                  WEIGHT=1
                  if [[ $i == 1 ]]; then
                    WEIGHT=10
                  fi
                  echo "weight.$i=$WEIGHT" >> /conf/zoo.cfg;
              done &&
              zkServer.sh start-foreground
          readinessProbe:
            exec:
              command:
                - bash
                - -c
                - '
                  IFS=;
                  MNTR=$(exec 3<>/dev/tcp/127.0.0.1/2181 ; printf "mntr" >&3 ; tee <&3; exec 3<&- ;);
                  while [[ "$MNTR" == "This ZooKeeper instance is not currently serving requests" ]];
                  do
                    echo "wait mntr works";
                    sleep 1;
                    MNTR=$(exec 3<>/dev/tcp/127.0.0.1/2181 ; printf "mntr" >&3 ; tee <&3; exec 3<&- ;);
                  done;
                  STATE=$(echo -e $MNTR | grep zk_server_state | cut -d " " -f 2);
                  if [[ "$STATE" =~ "leader" ]]; then
                    echo "check leader state";
                    SYNCED_FOLLOWERS=$(echo -e $MNTR | grep zk_synced_followers | awk -F"[[:space:]]+" "{print \$2}" | cut -d "." -f 1);
                    if [[ "$SYNCED_FOLLOWERS" != "0" ]]; then
                      ./bin/zkCli.sh ls /;
                      exit $?;
                    else
                      exit 0;
                    fi;
                  elif [[ "$STATE" =~ "follower" ]]; then
                    echo "check follower state";
                    PEER_STATE=$(echo -e $MNTR | grep zk_peer_state);
                    if [[ "$PEER_STATE" =~ "following - broadcast" ]]; then
                      ./bin/zkCli.sh ls /;
                      exit $?;
                    else
                      exit 1;
                    fi;
                  else
                    exit 1;
                  fi
                   '
            initialDelaySeconds: 15
            periodSeconds: 10
            timeoutSeconds: 60
          livenessProbe:
            exec:
              command:
                - bash
                - -xc
                - 'date && OK=$(exec 3<>/dev/tcp/127.0.0.1/2181 ; printf "ruok" >&3 ; IFS=; tee <&3; exec 3<&- ;); if [[ "$OK" == "imok" ]]; then exit 0; else exit 1; fi'
            initialDelaySeconds: 10
            periodSeconds: 30
            timeoutSeconds: 5
          volumeMounts:
            - name: datadir-volume
              mountPath: /var/lib/zookeeper
      # Run as a non-privileged user
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
      volumes:
        - name: datadir-volume
          emptyDir:
            medium: "" #accepted values:  empty str (means node's default medium) or Memory
            sizeLimit: 1Gi
```
    
æ¥è‘— apply è©²éƒ¨ç½²æ–‡ä»¶å’Œç¢ºèª zookeeper æ˜¯å¦éƒ½å·²å»ºç«‹ï¼š
    
```bash
# éƒ¨ç½²é…ç½®
kubectl apply -f zookeeper-3-nodes.yaml -n zoo3ns

# ç¢ºèª service
kubectl get svc -n zoo3ns
NAME        TYPE        CLUSTER-IP          EXTERNAL-IP   PORT(S)            AGE
zookeeper   ClusterIP   {YOUR-CLUSTER-IP}   <none>        2181/TCP,7000/TCP  54m
zookeepers  ClusterIP   None                <none>        2888/TCP,3888/TCP  54m

# ç¢ºèª pods
kubectl get pod -n zoo3ns
NAME            READY   STATUS    RESTARTS   AGE
zookeeper-0     1/1     Running   0          53m
zookeeper-1     1/1     Running   0          53m
zookeeper-2     1/1     Running   0          52m
```

5. éƒ¨ç½² Clickhouse with 1 shards and 2 replicas
```yaml
# clickhouse-1shards-2replicas.yaml
apiVersion: "clickhouse.altinity.com/v1"
kind: "ClickHouseInstallation"

metadata:
  name: "repl-05"

spec:
  defaults:
    templates:
      dataVolumeClaimTemplate: default
      podTemplate: clickhouse-20.7

  configuration:
    zookeeper:
      nodes:
      - host: zookeeper.zoo3ns
    clusters:
      - name: replicated
        layout:
          shardsCount: 1
          replicasCount: 2

  templates:
    volumeClaimTemplates:
      - name: default
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 500Mi
    podTemplates:
      - name: clickhouse-20.7
        spec:
          containers:
            - name: clickhouse-pod
              image: clickhouse/clickhouse-server:24.8
```

æ¥è‘— apply è©²éƒ¨ç½²æ–‡ä»¶å’Œç¢ºèª zookeeper æ˜¯å¦éƒ½å·²å»ºç«‹ï¼š
```bash
# éƒ¨ç½²é…ç½®
kubectl apply -f clickhouse-1shards-2replicas.yaml -n zoo3ns

# ç¢ºèª service
kubectl get svc -n zoo3ns
NAME                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
chi-repl-05-replicated-0-0   ClusterIP   None            <none>        9000/TCP,8123/TCP,9009/TCP   50m
chi-repl-05-replicated-0-1   ClusterIP   None            <none>        9000/TCP,8123/TCP,9009/TCP   49m
clickhouse-repl-05           ClusterIP   None            <none>        8123/TCP,9000/TCP            49m

# ç¢ºèª pods
kubectl get pod -n zoo3ns
NAME                           READY   STATUS    RESTARTS   AGE
chi-repl-05-replicated-0-0-0   1/1     Running   0          50m
chi-repl-05-replicated-0-1-0   1/1     Running   0          50m
```

å¦‚æœéƒ½å®Œæˆäº†ï¼Œæ­å–œä½ å®Œæˆæœ€é›£çš„ä¸€æ­¥ğŸš€ï¼š**å»ºç½®ç’°å¢ƒ**

6. é€²å…¥ ClickHouse å…§éƒ¨æ¸¬è©¦æ˜¯å¦æˆåŠŸ
    * é–‹å•Ÿå…©å€‹ terminalï¼Œå€‹åˆ¥é€²å…¥ä¸åŒçš„ pods
        ```bash
        kubectl exec -it chi-repl-05-replicated-0-0-0 -- bash
        kubectl exec -it chi-repl-05-replicated-0-1-0 -- bash
        ```
    * é€²å…¥å¾Œè¼¸å…¥ `clickhouse-client`
    * åœ¨ `chi-repl-05-replicated-0-0-0` pod å…§éƒ¨å»ºç«‹ `ReplicatedMergeTree`ï¼Œé€™å€‹ MergeTree å¼•æ“å¯ä»¥å¹«åŠ©ä½ è‡ªå‹•åŒæ­¥ä¸åŒ cluster, shards, replicas... çš„è³‡æ–™

    ```sql
    CREATE TABLE events_local ON CLUSTER `{cluster}`
    (
        `event_date` Date,
        `event_type` Int32,
        `article_id` Int32,
        `title` String
    )
    ENGINE = ReplicatedMergeTree('/clickhouse/{installation}/{cluster}/tables/{shard}/{database}/{table}', '{replica}')
    PARTITION BY toYYYYMM(event_date)
    ORDER BY (event_type, article_id)
    ```
    å¾—åˆ°çµæœï¼Œä»£è¡¨ä½ å·²ç¶“æˆåŠŸæ–°å¢äº†ã€‚
    ```sql
    Query id: 0e9d3beb-59ea-4194-9dbe-9f7cf88e19cc

    â”Œâ”€hostâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€portâ”€â”¬â”€statusâ”€â”¬â”€errorâ”€â”¬â”€num_hosts_remainingâ”€â”¬â”€num_hosts_activeâ”€â”
    1. â”‚ chi-repl-05-replicated-0-0 â”‚ 9000 â”‚      0 â”‚       â”‚                   1 â”‚                0 â”‚
    2. â”‚ chi-repl-05-replicated-0-1 â”‚ 9000 â”‚      0 â”‚       â”‚                   0 â”‚                0 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    2 rows in set. Elapsed: 0.253 sec.
    ```
    * æ¥è‘—å»ºç«‹æœ¬åœ°è¡¨

    ```sql
    CREATE TABLE events ON CLUSTER `{cluster}` AS events_local
    ENGINE = Distributed('{cluster}', default, events_local, rand())
    ```

    å¾—åˆ°çµæœï¼Œä»£è¡¨ä½ å·²ç¶“æˆåŠŸæ–°å¢äº†ã€‚

    ```sql
    Query id: b203ec4b-08b1-45bf-98ea-6d4ad32956d8

    â”Œâ”€hostâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€portâ”€â”¬â”€statusâ”€â”¬â”€errorâ”€â”¬â”€num_hosts_remainingâ”€â”¬â”€num_hosts_activeâ”€â”
    1. â”‚ chi-repl-05-replicated-0-0 â”‚ 9000 â”‚      0 â”‚       â”‚                   1 â”‚                0 â”‚
    2. â”‚ chi-repl-05-replicated-0-1 â”‚ 9000 â”‚      0 â”‚       â”‚                   0 â”‚                0 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    2 rows in set. Elapsed: 0.084 sec.
    ```

    * æ¥è‘—å¯ä»¥åœ¨ `chi-repl-05-replicated-0-0-0` æ’å…¥è³‡æ–™ï¼Œåœ¨ `chi-repl-05-replicated-0-1-0` è§€å¯Ÿè³‡æ–™æ˜¯å¦æœ‰åŒæ­¥
        * å…ˆåœ¨ `chi-repl-05-replicated-0-1-0` è§€å¯Ÿï¼Œæ²’æœ‰è³‡æ–™æ˜¯æ­£å¸¸çš„:
        ```sql
        SELECT *
        FROM events_local
        WHERE event_type = 100

        Query id: 4dd7fbbd-4089-4b7a-aa16-af78baeaf3f4

        Ok.

        0 rows in set. Elapsed: 0.002 sec.
        ```
        * åœ¨ `chi-repl-05-replicated-0-0-0` æ’å…¥è³‡æ–™
        ```sql
        INSERT INTO events VALUES (today(), 100, 123, 'from pod A');
        ```
        * å›åˆ° `chi-repl-05-replicated-0-1-0` è§€å¯Ÿ:
        ```sql
        SELECT *
        FROM events_local
        WHERE event_type = 100

        Query id: 1537f542-a13d-4a19-b29b-baed69b476c8

        â”Œâ”€event_dateâ”€â”¬â”€event_typeâ”€â”¬â”€article_idâ”€â”¬â”€titleâ”€â”€â”€â”€â”€â”€â”
        1. â”‚ 2025-08-28 â”‚        100 â”‚        123 â”‚ from pod A â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        1 row in set. Elapsed: 0.002 sec.
        ```

åˆ°é€™é‚Šéƒ½æ˜¯æ­£ç¢ºçš„ï¼Œä»£è¡¨ä½ æˆåŠŸäº†ï¼ï¼ï¼ï¼ˆä½†æ˜¯æ˜¯åœ¨å–®ç¯€é»ä¸Šï¼‰

## éƒ¨ç½²éç¨‹ä¸­çš„æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆ

å³ä¾¿æœ‰äº† Operatorï¼Œä»ç„¶æœƒé‡åˆ°ä¸€äº›æŒ‘æˆ°ï¼š

* **å„²å­˜ç®¡ç†**
  * PVC å¤§å°éœ€äº‹å…ˆè¦åŠƒï¼Œå¦å‰‡å¾ŒæœŸèª¿æ•´éº»ç…©ã€‚
  * è§£æ³•ï¼šä½¿ç”¨ StorageClass æä¾›å‹•æ…‹æ“´å±•ã€‚

* **å‡ç´šç­–ç•¥**
  * ç›´æ¥å‡ç´šå¯èƒ½å°è‡´ç¯€é»ä¸ä¸€è‡´ã€‚
  * è§£æ³•ï¼šä½¿ç”¨ Rolling Updateï¼Œä¸¦ç¢ºä¿è¡¨æ ¼å¼•æ“ç‚º Replicated ç³»åˆ—ã€‚

* **ç›£æ§èˆ‡è§€æ¸¬æ€§**
  * æŸ¥è©¢æ•ˆèƒ½ä¸‹é™æ™‚éœ€è¦å¿«é€Ÿè¨ºæ–·ã€‚
  * è§£æ³•ï¼šçµåˆ Prometheus + Grafanaï¼Œç›£æ§ query latencyã€merge æ•¸é‡ã€ç£ç¢Ÿä½¿ç”¨ç‡ã€‚

* **ç¶²è·¯èˆ‡æµé‡åˆ†é…**
  * å¤š Shard æŸ¥è©¢éœ€é€é Distributed Table æˆ–å¤–éƒ¨è² è¼‰å¹³è¡¡ã€‚
  * è§£æ³•ï¼šKubernetes Ingress + ClickHouse Distributed Engineã€‚

## èˆ‡å‚³çµ± VM éƒ¨ç½²çš„å·®ç•°

| é¢å‘   | VM/è£¸æ©Ÿéƒ¨ç½²         | Kubernetes éƒ¨ç½²         |
| ---- | --------------- | --------------------- |
| éƒ¨ç½²æ–¹å¼ | æ‰‹å‹•å®‰è£ã€é…ç½®         | YAML å®šç¾©ã€è‡ªå‹•åŒ–           |
| æ“´å®¹   | éœ€äººå·¥åŠ æ©Ÿå™¨ã€æ”¹è¨­å®š      | ä¿®æ”¹ replicas/shards å³å¯ |
| é«˜å¯ç”¨  | éœ€äººå·¥ç¶­è­· Zookeeper | Operator è‡ªå‹•å”èª¿         |
| å‡ç´š   | å®¹æ˜“åœæ©Ÿ            | æ»¾å‹•æ›´æ–°ã€é›¶åœæ©Ÿ              |
| ç›£æ§   | é¡å¤–å®‰è£            | Prometheus/Grafana æ•´åˆ |

çµè«–å¾ˆæ˜é¡¯ï¼šå¦‚æœä½ æ˜¯å–®æ©Ÿæ¸¬è©¦ï¼ŒVM éƒ¨ç½²å³å¯ï¼›ä½†è‹¥è¦é€²å…¥ç”Ÿç”¢ç’°å¢ƒï¼ŒKubernetes + Operator å¹¾ä¹æ˜¯æ¨™æº–è§£ã€‚

## çµèª

ClickHouse æœ¬èº«éå¸¸å¼·å¤§ï¼Œä½†è‹¥ç¼ºä¹å¥½çš„éƒ¨ç½²æ–¹å¼ï¼Œå®¹æ˜“å› ç¯€é»æ•…éšœã€æ“´å±•å›°é›£ã€å‡ç´šä¸ä¾¿è€Œå½±éŸ¿ç©©å®šæ€§ã€‚Kubernetes èˆ‡ ClickHouse Operator çš„çµåˆï¼Œè®“æˆ‘å€‘èƒ½ï¼š

* ä»¥ **å®£å‘Šå¼é…ç½® (YAML)** ç®¡ç†æ•´å€‹å¢é›†
* è‡ªå‹•åŒ–å®Œæˆ **éƒ¨ç½²ã€å‡ç´šã€æ“´å±•**
* æä¾›é«˜å¯ç”¨èˆ‡å®¹éŒ¯èƒ½åŠ›ï¼Œæ”¯æ´é›²ç«¯è¦æ¨¡çš„æ•¸æ“šåˆ†æ

åœ¨è³‡æ–™é‡ä¸æ–·æˆé•·çš„ä»Šå¤©ï¼Œé€™ç¨®é›²åŸç”Ÿéƒ¨ç½²æ–¹å¼å·²æˆç‚º ClickHouse ç”Ÿç”¢ç’°å¢ƒçš„é¦–é¸ã€‚

æ˜å¤©å°±æ˜¯ ClickHouse ç³»åˆ—æœ€å¾Œä¸€å¤©äº†ï¼šï¼¤


### ClickHouse ç³»åˆ—æŒçºŒæ›´æ–°ä¸­:

1. [ClickHouse ç³»åˆ—ï¼šClickHouse æ˜¯ä»€éº¼ï¼Ÿèˆ‡å‚³çµ± OLAP/OLTP è³‡æ–™åº«çš„å·®ç•°](https://blog.vicwen.app/posts/what-is-clickhouse/)
2. [ClickHouse ç³»åˆ—ï¼šClickHouse ç‚ºä»€éº¼é¸æ“‡ Column-based å„²å­˜ï¼Ÿè¬›è§£ Row-based èˆ‡ Column-based çš„æ ¸å¿ƒå·®ç•°](https://blog.vicwen.app/posts/clickhouse-column-row-based-storage/)
3. [ClickHouse ç³»åˆ—ï¼šClickHouse å„²å­˜å¼•æ“ - MergeTree](https://blog.vicwen.app/posts/clickhouse-mergetree-engine)
4. [ClickHouse ç³»åˆ—ï¼šå£“ç¸®æŠ€è¡“èˆ‡ Data Skipping Indexes å¦‚ä½•å¤§å¹…åŠ é€ŸæŸ¥è©¢](https://blog.vicwen.app/posts/clickhouse-compression-skipping-index/)
5. [ClickHouse ç³»åˆ—ï¼šReplacingMergeTree èˆ‡è³‡æ–™å»é‡æ©Ÿåˆ¶](https://blog.vicwen.app/posts/clickhouse-replacingmergetree-deduplication/)
6. [ClickHouse ç³»åˆ—ï¼šSummingMergeTree é€²è¡Œè³‡æ–™å½™ç¸½çš„æ‡‰ç”¨å ´æ™¯](https://blog.vicwen.app/posts/clickhouse-summingmergetree-aggregation/)
7. [ClickHouse ç³»åˆ—ï¼šMaterialized Views å³æ™‚èšåˆæŸ¥è©¢](https://blog.vicwen.app/posts/clickhouse-materialized-view/)
8. [ClickHouse ç³»åˆ—ï¼šåˆ†å€ç­–ç•¥èˆ‡ Partition Pruning åŸç†è§£æ](https://blog.vicwen.app/posts/clickhouse-partition-pruning/)
9. [ClickHouse ç³»åˆ—ï¼šPrimary Keyã€Sorting Key èˆ‡ Granule ç´¢å¼•é‹ä½œåŸç†](https://blog.vicwen.app/posts/clickhouse-primary-sorting-key/)
10. [ClickHouse ç³»åˆ—ï¼šCollapsingMergeTree èˆ‡é‚è¼¯åˆªé™¤çš„æœ€ä½³å¯¦è¸](https://blog.vicwen.app/posts/clickhouse-collapsingmergetree/)
11. [ClickHouse ç³»åˆ—ï¼šVersionedCollapsingMergeTree ç‰ˆæœ¬æ§åˆ¶èˆ‡è³‡æ–™è¡çªè§£æ±º](https://blog.vicwen.app/posts/clickhouse-versioned-collapsingmergetree/)
12. [ClickHouse ç³»åˆ—ï¼šAggregatingMergeTree å¯¦æ™‚æŒ‡æ¨™çµ±è¨ˆçš„é€²éšæ‡‰ç”¨](https://blog.vicwen.app/posts/clickhouse-aggregatingmergetree/)
13. [ClickHouse ç³»åˆ—ï¼šDistributed Table èˆ‡åˆ†å¸ƒå¼æŸ¥è©¢æ¶æ§‹](https://blog.vicwen.app/posts/clickhouse-distributed-table-architecture/)
14. [ClickHouse ç³»åˆ—ï¼šReplicated Tables é«˜å¯ç”¨æ€§èˆ‡é›¶åœæ©Ÿå‡ç´šå¯¦ä½œ](https://blog.vicwen.app/posts/clickhouse-replication-failover/)
15. [ClickHouse ç³»åˆ—ï¼šèˆ‡ Kafka æ•´åˆæ‰“é€ å³æ™‚ Data Streaming Pipeline](https://blog.vicwen.app/posts/clickhouse-kafka-data-streaming-pipeline/)
16. [ClickHouse ç³»åˆ—ï¼šæ‰¹æ¬¡åŒ¯å…¥æœ€ä½³å¯¦è¸ (CSVã€Parquetã€Native Format)](https://blog.vicwen.app/posts/clickhouse-batch-import/)
17. [ClickHouse ç³»åˆ—ï¼šClickHouse èˆ‡å¤–éƒ¨è³‡æ–™æºæ•´åˆï¼ˆPostgreSQLï¼‰](https://blog.vicwen.app/posts/clickhouse-external-data-integration/)
18. [ClickHouse ç³»åˆ—ï¼šå¦‚ä½•æå‡æŸ¥è©¢å„ªåŒ–ï¼Ÿsystem.query_log èˆ‡ EXPLAIN ç”¨æ³•](https://blog.vicwen.app/posts/clickhouse-query-log-explain/)
19. [ClickHouse ç³»åˆ—ï¼šProjections é€²éšæŸ¥è©¢åŠ é€ŸæŠ€è¡“](https://blog.vicwen.app/posts/clickhouse-projections-optimization/)
20. [ClickHouse ç³»åˆ—ï¼šSampling æŠ½æ¨£æŸ¥è©¢èˆ‡çµ±è¨ˆæŠ€è¡“åŸç†](https://blog.vicwen.app/posts/clickhouse-sampling-statistics/)
21. [ClickHouse ç³»åˆ—ï¼šTTL è³‡æ–™æ¸…ç†èˆ‡å„²å­˜æˆæœ¬å„ªåŒ–](https://blog.vicwen.app/posts/clickhouse-ttl-storage-management/)
22. [ClickHouse ç³»åˆ—ï¼šå„²å­˜æ”¿ç­–ï¼ˆStorage Policiesï¼‰èˆ‡ç£ç¢Ÿè³‡æºåˆ†å±¤ç­–ç•¥](https://blog.vicwen.app/posts/clickhouse-storage-policies/)
23. [ClickHouse ç³»åˆ—ï¼šè¡¨æ ¼è¨­è¨ˆèˆ‡å„²å­˜å„ªåŒ–ç´°ç¯€](https://blog.vicwen.app/posts/clickhouse-schemas-storage-improvement/)
24. [ClickHouse ç³»åˆ—ï¼šClickHouse ç³»åˆ—ï¼šæ•´åˆ Grafana æ‰“é€ å¯è¦–åŒ–ç›£æ§](https://blog.vicwen.app/posts/clickhouse-grafana-dashboard/)
25. [ClickHouse ç³»åˆ—ï¼šæŸ¥è©¢å„ªåŒ–æ¡ˆä¾‹](https://blog.vicwen.app/posts/clickhouse-select-optimization/)
26. [ClickHouse ç³»åˆ—ï¼šèˆ‡ BI å·¥å…·æ•´åˆï¼ˆPower BIï¼‰](https://blog.vicwen.app/posts/clickhouse-bi-integration/)
27. [ClickHouse ç³»åˆ—ï¼šClickHouse Cloud èˆ‡è‡ªå»ºéƒ¨ç½²çš„å„ªåŠ£æ¯”è¼ƒ](https://blog.vicwen.app/posts/clickhouse-cloud-vs-self-host/)
28. [ClickHouse ç³»åˆ—ï¼šè³‡æ–™åº«å®‰å…¨æ€§èˆ‡æ¬Šé™ç®¡ç†ï¼ˆRBACï¼‰å¯¦ä½œ](https://blog.vicwen.app/posts/clickhouse-security-rbac/)
29. [ClickHouse ç³»åˆ—ï¼šKubernetes éƒ¨ç½²åˆ†æ•£å¼æ¶æ§‹](https://blog.vicwen.app/posts/clickhouse-operator-kubernates/)
30. [ClickHouse ç³»åˆ—ï¼šå¾åŸå§‹ç¢¼çœ‹ MergeTree çš„å…­å¤§æ ¸å¿ƒæ©Ÿåˆ¶](https://blog.vicwen.app/posts/clickhouse-mergetree-sourcecode-introduction/)